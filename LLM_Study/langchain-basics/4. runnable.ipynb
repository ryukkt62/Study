{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "\n",
    "# llm.invoke(\"What is the capital of the France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of France? Return the name of the capital only.'\n",
      "content='Paris.' additional_kwargs={} response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-03-13T08:01:21.392357Z', 'done': True, 'done_reason': 'stop', 'total_duration': 8132660916, 'load_duration': 7744735041, 'prompt_eval_count': 40, 'prompt_eval_duration': 371000000, 'eval_count': 3, 'eval_duration': 15000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-8bb1a5d0-5ae6-4fbb-8efe-effc968fdb3d-0' usage_metadata={'input_tokens': 40, 'output_tokens': 3, 'total_tokens': 43}\n"
     ]
    }
   ],
   "source": [
    "# prompt template\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}? Return the name of the capital only.\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"country\": \"France\"})\n",
    "print(prompt)\n",
    "\n",
    "ai_message = llm.invoke(prompt_template.invoke({\"country\": \"France\"}))\n",
    "print(ai_message)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "answer = output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\": \"France\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 llm이 BaseChatModel을 상속받음(ollama, gpt, claude, etc)\n",
    "# BaseChatModel은 runnable을 상속받음\n",
    "# runnable에 invoke가 있음. 그렇기 때문에 다 Invoke를 하는 것임 \n",
    "# 그렇기 때문에 langchain에서는 모든 것이 runnable임 \n",
    "\n",
    "# runnable들로 chain을 만들 것임\n",
    "# runnable은 실행가능한 것들\n",
    "# |는 파이프를 의미함\n",
    "\n",
    "# output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\": \"France\"}))을 반대로 넘겨주면 됨\n",
    "# 앞에서 뒤로 넘겨주다보니 가독성이 좋음 \n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "capital_chain.invoke({\"country\": \"France\"}) # capital_chain도 runnable이다보니 invoke가 됨. 또한 파이프에 연결될 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_prompt = PromptTemplate( \n",
    "    template=\"\"\"Guess the name of the country in the country based on the following information:\n",
    "    {information}\n",
    "    Return the name of the country only.\n",
    "    \"\"\",\n",
    "    input_variables=[\"information\"],\n",
    ")\n",
    "\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "country_chain.invoke({\"information\": \"This country is very famous for its wine in Europe.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = country_chain | capital_chain\n",
    "\n",
    "# country_chain의 결과를 capital_chain에게 줌.\n",
    "# 근데 capital_chain은 country가 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = {\"country\":country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그리고 final_chain의 Invoke를 다음과 같이 함\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine in Europe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnablePassthrough라는게 있음\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\": RunnablePassthrough()} | {\"country\": country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\"information\":\"This country is very famous for its wine in Europe\"}) #{}가 하나만 필요하기때문에 굳이 information: 이렇게 안써도 됨\n",
    "\n",
    "# invoke안의 정보가 바로 위 Cell의 Information으로 들어가서 위의 country_chain의 invoke에 있는 information에 들어감\n",
    "# 그럼 그 답변이 country가 되서, 또 그 country가 capital_chain에게 들어감 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnablePassthrough의 또다른 팁\n",
    "# {}가 2개면, (information, continent)\n",
    "# key를 다 지정해줘야함\n",
    "# final_chain.invoke({\"information\": \"This country is very famous for its wine in Europe\", \"continent\": \"Europe\"})\n",
    "\n",
    "# 아래처럼하면 에러남\n",
    "# final_chain.invoke({\"This country is very famous for its wine in Europe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_prompt = PromptTemplate( \n",
    "    template=\"\"\"Guess the name of the country in the {continent} based on the following information:\n",
    "    {information}\n",
    "    Return the name of the country only.\n",
    "    \"\"\",\n",
    "    input_variables=[\"information\",'continent'],\n",
    ")\n",
    "\n",
    "country_chain = country_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnable Passthrough\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\": RunnablePassthrough(), \"continent\": RunnablePassthrough()} | {\"country\": country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke({\"information\": \"This country is very famous for its wine in Europe\", \"continent\": \"Europe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
